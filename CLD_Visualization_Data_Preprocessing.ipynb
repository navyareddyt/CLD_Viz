{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdBcfQt8NIQK"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jSC7vEJNNKfi"
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, SelectMultiple\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86y7ezSpNMku"
   },
   "source": [
    "# Data Processing for Gender Distribution across Legislatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_dict.json file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = \"Core_updated.xlsx\"\n",
    "workbook = openpyxl.load_workbook(file_path)\n",
    "\n",
    "# Get the sheet names and store them in a tuple\n",
    "sheet_names = tuple(workbook.sheetnames)\n",
    "\n",
    "# Initialize an empty gender dictionary\n",
    "gender_dict = {}\n",
    "\n",
    "# Iterate through each sheet\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    # Get the current sheet\n",
    "    sheet = workbook[sheet_name]\n",
    "\n",
    "    # Initialize counts for male and female\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    # Iterate through rows starting from the second row\n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "        sex = row[5]  \n",
    "        if sex == 'male':\n",
    "            male_count += 1\n",
    "        elif sex == 'female':\n",
    "            female_count += 1\n",
    "\n",
    "    # Store counts in the gender dictionary\n",
    "    gender_dict[sheet_name] = (male_count, female_count)\n",
    "    \n",
    "gender_dict = dict(sorted(gender_dict.items(), key=lambda item: sum(item[1])))\n",
    "\n",
    "# Print the sheet names tuple and the gender dictionary\n",
    "#print(\"Legislature Names:\", sheet_names)\n",
    "#print(\"Gender Dictionary:\", gender_dict)\n",
    "\n",
    "# Save gender_dict as a JSON file\n",
    "with open('gender_dict.json', 'w') as json_file:\n",
    "    json.dump(gender_dict, json_file)\n",
    "\n",
    "print(\"gender_dict.json file has been created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V33FAZvxb1zC"
   },
   "source": [
    "# Data Processing for Social Media Distribution across Legislatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social_media_dict.json file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = \"Social_updated.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Define the columns to consider\n",
    "social_media_columns = ['twitter', 'facebook', 'youtube', 'instagram', 'website', 'linkedin']\n",
    "\n",
    "# Initialize an empty dictionary to store the counts\n",
    "social_media_dict = {}\n",
    "\n",
    "# Iterate through each sheet\n",
    "for sheet_name in xls.sheet_names:\n",
    "    # Read the sheet into a DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name)\n",
    "\n",
    "    # Get the country name\n",
    "    country_name = sheet_name\n",
    "\n",
    "    # Get counts for each social media platform\n",
    "    counts = []\n",
    "    for column in social_media_columns:\n",
    "        if column in df.columns:\n",
    "            # Count the non-null values for each column\n",
    "            counts.append(int(df[column].count()))\n",
    "        else:\n",
    "            counts.append(0) \n",
    "\n",
    "    # Add counts to the dictionary with country name as key\n",
    "    social_media_dict[country_name] = counts\n",
    "\n",
    "# Save social_media_dict as a JSON file\n",
    "with open('social_media_dict.json', 'w') as json_file:\n",
    "    json.dump(social_media_dict, json_file)\n",
    "\n",
    "print(\"social_media_dict.json file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQxKwTn3oqWw"
   },
   "source": [
    "# Data Processing for Traffic on Wikipedia across Legislatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_df.csv file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the main directory\n",
    "traffic_directory = \"Traffic/\"\n",
    "\n",
    "# Define the mapping of current column names to new names\n",
    "column_mapping = {\n",
    "    'isr_traffic.csv': 'Israel',\n",
    "    'sco_traffic.csv': 'Scotland',\n",
    "    'can_traffic.csv': 'Canada',\n",
    "    'bra_traffic.csv': 'Brazil',\n",
    "    'tur_traffic.csv': 'Turkey',\n",
    "    'jpn_traffic.csv': 'Japan',\n",
    "    'usa_senate_traffic.csv': 'United States Senate',\n",
    "    'gbr_traffic.csv': 'United Kingdom',\n",
    "    'deu_traffic.csv': 'Germany',\n",
    "    'fra_traffic.csv': 'France',\n",
    "    'usa_house_traffic.csv': 'United States House',\n",
    "    'ita_house_traffic.csv': 'Italy House',\n",
    "    'cze_traffic.csv': 'Czech Republic',\n",
    "    'nld_traffic.csv': 'Netherlands',\n",
    "    'ita_senate_traffic.csv': 'Italy Senate',\n",
    "    'irl_traffic.csv': 'Ireland',\n",
    "    'esp_traffic.csv': 'Spain',\n",
    "    'aut_traffic.csv': 'Austria'\n",
    "}\n",
    "\n",
    "# Initialize an empty dictionary to store the traffic_dict\n",
    "traffic_dict = {}\n",
    "\n",
    "# Get the range of years across all legislatures\n",
    "min_year = float('inf')\n",
    "max_year = float('-inf')\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(traffic_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(traffic_directory, filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if 'date' in df.columns and 'traffic' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df['year'] = df['date'].dt.year\n",
    "\n",
    "            # Update the minimum and maximum years\n",
    "            min_year = min(min_year, df['year'].min())\n",
    "            max_year = max(max_year, df['year'].max())\n",
    "\n",
    "            # Group by year and calculate the sum of traffic\n",
    "            traffic_by_year = df.groupby('year')['traffic'].sum()\n",
    "\n",
    "            # Store the sums in the dictionary\n",
    "            legislature_name = column_mapping[filename]\n",
    "            traffic_dict[legislature_name] = traffic_by_year\n",
    "\n",
    "# Create a DataFrame with years as index\n",
    "index = pd.RangeIndex(start=min_year, stop=max_year+1, name='Year')\n",
    "traffic_df = pd.DataFrame(index=index)\n",
    "\n",
    "# Fill the DataFrame with traffic data\n",
    "for legislature, data in traffic_dict.items():\n",
    "    traffic_df[legislature] = data\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "traffic_df = traffic_df.replace({np.nan: ''})\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "traffic_df.to_csv('traffic_df.csv')\n",
    "\n",
    "print(\"traffic_df.csv file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing for Religion Distribution across Legislatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion_dict.json file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = \"Core_updated.xlsx\"\n",
    "workbook = openpyxl.load_workbook(file_path)\n",
    "\n",
    "# Get the sheet names and store them in a tuple\n",
    "sheet_names = tuple(workbook.sheetnames)\n",
    "\n",
    "# Mapping of individual religions to broader categories\n",
    "religion_mapping = {\n",
    "    'Christianity': ['catholicism', 'orthodox eastern', 'protestantism', 'protestantism hussite', 'protestantism methodist', 'protestantism lutheran', 'protestantism anglican', 'protestantism anglicanism', 'anglicanism', 'protestantism baptism', 'protestantism baptist', 'protestantism presbyterian', 'protestantism adventist', 'protestantism pentecostal', 'protestantism quaker', 'protestantism restorationism', 'protestantism reformed', 'protestantism evangelical', 'protestantism anabaptism', 'protestantism arminianism', 'protestantism nontrinitarian', 'protestantism unitarian', 'protestantism christian science', 'protestantism non-denominational', 'protestantism apostolic', 'protestantism proto'],\n",
    "    'Islam': ['islam'],\n",
    "    'Hinduism': ['hindu'],\n",
    "    'Buddhism': ['buddhism', 'nichiren shu', 'jodo_shinshu', 'soka gakkai'],\n",
    "    'Judaism': ['judaism', 'orthodox', 'conservative', 'reform'],\n",
    "}\n",
    "#Others include : atheism,honganji-ha,confucianism,happy science,tenrikyo,yazidism,alevism,agnosticism,sikhism,zoroastrianism,druze,candomblé,bahá'í_faith\n",
    "\n",
    "# Define the columns to consider\n",
    "religion_columns = ['Christianity', 'Islam', 'Hinduism', 'Buddhism', 'Judaism', 'Others']\n",
    "\n",
    "# Initialize a dictionary to store country-wise religion counts\n",
    "religion_dict = {}\n",
    "\n",
    "# Iterate through each sheet\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    # Get the current sheet\n",
    "    sheet = workbook[sheet_name]\n",
    "\n",
    "    # Initialize country-wise religion counts\n",
    "    country_religion_count = {'Christianity': 0, 'Islam': 0, 'Hinduism': 0, 'Buddhism': 0, 'Judaism': 0, 'Others': 0}\n",
    "\n",
    "\n",
    "    # Iterate through rows starting from the second row \n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "        religion = row[6]  \n",
    "        # Check the mapping to determine the broader category\n",
    "        for category, religions_list in religion_mapping.items():\n",
    "            if religion in religions_list:\n",
    "                country_religion_count[category] += 1\n",
    "                break\n",
    "        else:\n",
    "            country_religion_count['Others'] += 1\n",
    "\n",
    "\n",
    "    # Initialize counts tuple\n",
    "    counts_tuple = ()\n",
    "\n",
    "    for column in religion_columns:\n",
    "      counts_tuple += (country_religion_count[column],)\n",
    "\n",
    "\n",
    "    # Store country-wise religion counts in the dictionary\n",
    "    religion_dict[sheet_name] = counts_tuple\n",
    "\n",
    "# Print the sheet names tuple and the country-wise religion counts\n",
    "#print(\"Legislature Names:\", sheet_names)\n",
    "#print(\"Country-wise Religion Counts:\", religion_dict)\n",
    "\n",
    "with open('religion_dict.json', 'w') as json_file:\n",
    "    json.dump(religion_dict, json_file)\n",
    "\n",
    "print(\"religion_dict.json file has been created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
